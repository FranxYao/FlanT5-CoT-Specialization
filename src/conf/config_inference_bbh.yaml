defaults:
  - _self_
  - device_map: 11b_inference
  - iter: 3b # 3b, 780m
  - override hydra/hydra_logging: disabled  
  - override hydra/job_logging: disabled  

model_version: "0.0.2.2.1"
epoch: "0"
base_model: /mnt/data_10t/flan_t5_distill/checkpoints/${model_version}_epoch_${epoch}_
model_size: 3b
gpu_id: "0"
tokenizer: google/flan-t5-xl
prompt_mode: cot # cot or ao
# batch_size: 50
# test_data:
batch_size:
  boolean_expressions: 50
  causal_judgement: 50
  date_understanding: 50
  disambiguation_qa: 50
  dyck_languages: 50
  formal_fallacies: 50
  geometric_shapes: 10
  hyperbaton: 50
  logical_deduction_five_objects: 50
  logical_deduction_seven_objects: 50
  logical_deduction_three_objects: 50
  movie_recommendation: 50
  multistep_arithmetic_two: 50
  navigate: 50
  object_counting: 50
  penguins_in_a_table: 50
  reasoning_about_colored_objects: 50
  ruin_names: 50
  salient_translation_error_detection: 20
  snarks: 50
  sports_understanding: 50
  temporal_sequences: 50
  tracking_shuffled_objects_five_objects: 50
  tracking_shuffled_objects_seven_objects: 50
  tracking_shuffled_objects_three_objects: 50
  web_of_lies: 50
  word_sorting: 50

output_path: /mnt/data_10t/flan_t5_distill/outputs/

hydra:  
  output_subdir: null  
  run:  
    dir: .